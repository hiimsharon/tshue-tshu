// publicCrawl.js

import puppeteer from 'puppeteer'
import { MongoClient } from 'mongodb'
import dotenv from 'dotenv'
dotenv.config()

const uri = process.env.MONGODB_URI
const client = new MongoClient(uri)
const dbName = 'tshue_tshu'
const collectionName = 'posts'

export async function crawlPublicPosts() {
  const browser = await puppeteer.launch({
    headless: 'new',
    args: ['--no-sandbox', '--disable-setuid-sandbox']
  })

  const page = await browser.newPage()

  // âœ… åŠ å…¥ User-Agentï¼ˆæå‡ç©©å®šæ€§ï¼‰
  await page.setUserAgent(
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/115.0'
  )

  // ğŸ‘‰ ç›®æ¨™ç¶²å€
  const url = process.env.CRAWL_URL || 'https://www.facebook.com/groups/2391145197642950/'
  await page.goto(url, { waitUntil: 'networkidle2', timeout: 0 })

  // ğŸ‘‰ æ“·å–è²¼æ–‡è³‡æ–™ï¼ˆå¯è‡ªè¨‚é‚è¼¯ï¼‰
  const posts = await page.evaluate(() => {
    const data = []
    document.querySelectorAll('div[data-ad-preview="message"]').forEach(post => {
      const text = post.innerText.trim()
      if (text) data.push({ text, createdAt: new Date().toISOString() })
    })
    return data
  })

  const now = new Date().toLocaleString()
  console.log(`[${now}] âœ… æ“·å–åˆ° ${posts.length} ç­†è²¼æ–‡`)

  try {
    await client.connect()
    const db = client.db(dbName)
    const collection = db.collection(collectionName)

    let insertedCount = 0

    for (const post of posts) {
      const exists = await collection.findOne({ text: post.text })
      if (!exists) {
        await collection.insertOne(post)
        insertedCount++
      }
    }

    console.log(`[${now}] ğŸ“¥ æˆåŠŸå¯«å…¥ ${insertedCount} ç­†æ–°è²¼æ–‡ï¼Œç•¥é ${posts.length - insertedCount} ç­†é‡è¤‡è²¼æ–‡`)
  } catch (err) {
    console.error(`[${now}] âŒ MongoDB å¯«å…¥å¤±æ•—ï¼š`, err)
  } finally {
    await client.close()
    await browser.close()
  }
}
